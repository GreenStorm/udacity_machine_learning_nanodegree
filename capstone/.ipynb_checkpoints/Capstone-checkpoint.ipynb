{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## **II. Analysis**\n",
    "\n",
    "*(approx. 2-4 pages)*\n",
    "\n",
    "### **Data Exploration**\n",
    "\n",
    "In this section, you will be expected to analyze the data you are using for the problem. This data can either be in the form of a dataset (or datasets), input data (or input files), or even an environment. The type of data should be thoroughly described and, if possible, have basic statistics and information presented (such as discussion of input features or defining characteristics about the input or environment). Any abnormalities or interesting qualities about the data that may need to be addressed have been identified (such as features that need to be transformed or the possibility of outliers). Questions to ask yourself when writing this section:\n",
    "\n",
    "* *If a dataset is present for this problem, have you thoroughly discussed certain features about the dataset? Has a data sample been provided to the reader?*\n",
    "\n",
    "* *If a dataset is present for this problem, are statistics about the dataset calculated and reported? Have any relevant results from this calculation been discussed?*\n",
    "\n",
    "* *If a dataset is not present for this problem, has discussion been made about the input space or input data for your problem?*\n",
    "\n",
    "* *Are there any abnormalities or characteristics about the input space or dataset that need to be addressed? (categorical variables, missing values, outliers, etc.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    nuclei_files = np.array(glob(path+'/*/images/*'))\n",
    "    nuclei_targets = np.array(glob(path+'/*/masks/*'))\n",
    "    return nuclei_files,nuclei_targets\n",
    "\n",
    "    \n",
    "def load_dataset_2(path):\n",
    "    training_paths = pathlib.Path(path).glob('*/images/*.png')\n",
    "    training_sorted = sorted([x for x in training_paths])\n",
    "    im_path = training_sorted[45]\n",
    "    im = imageio.imread(str(im_path))\n",
    "    #nuclei_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return nuclei_files#, nuclei_target\n",
    "\n",
    "train_files,train_targets = load_dataset('stage1_train/')\n",
    "test_files,test_targets= load_dataset('stage1_test/')\n",
    "\n",
    "#TODO: pick a better represntation of a validation set\n",
    "\n",
    "\n",
    "print('There are %d training batch nuecli images.' % len(train_files))\n",
    "print('There are %d training batch nuecli masks.' % len(train_targets))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (train_files[0])\n",
    "print (train_targets[1])\n",
    "sample_path = train_files[0]\n",
    "\n",
    "def get_filename(path):\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "def bind_mask_to_images(images_paths, masks_paths):\n",
    "    image_id = 0\n",
    "    filename = get_filename(images_paths[0])\n",
    "    masks_binded = [[]]\n",
    "    for mask_path in masks_paths:\n",
    "        if filename in mask_path:\n",
    "            masks_binded[image_id].append(mask_path)\n",
    "        else:\n",
    "            image_id = image_id+1\n",
    "            filename = get_filename(images_paths[image_id])\n",
    "            masks_binded.append([mask_path])\n",
    "    return np.array(masks_binded)\n",
    "\n",
    "train_targets_binded = bind_mask_to_images(train_files,train_targets)\n",
    "print(\"Train targets have been binded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(train_files[3])\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.imread(train_files[3],0)\n",
    "\n",
    "\n",
    "#from skimage.color import rgb2gray\n",
    "#im_gray = rgb2gray(img)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original image\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Greyscaled image\")\n",
    "plt.imshow(gray)\n",
    "plt.show()\n",
    "#pixel intensity for image\n",
    "plt.hist(gray.ravel(),256,[0,256])\n",
    "plt.title(\"Pixel intensity of the image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Code from: https://docs.opencv.org/3.1.0/d1/db7/tutorial_py_histogram_begins.html , https://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/ and dog-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "\n",
    "seed = random.seed(8675309)\n",
    "def find_dominant_color_in_image(image,number_of_clusters):\n",
    "    # re-shape our image to be a list of pixels, rather than MxN matrix of pixels\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    color_clf = KMeans(random_state=seed,n_clusters = number_of_clusters)\n",
    "    color_clf.fit(image)\n",
    "    \n",
    "    return color_clf.cluster_centers_\n",
    "\n",
    "def cluster_images_based_on_color(images_path_array,number_of_clusters,number_of_colors):\n",
    "    dominant_colors = []\n",
    "    for image_path in images_path_array:\n",
    "        image = cv2.imread(image_path)\n",
    "        colors_in_image = find_dominant_color_in_image(image,number_of_colors)\n",
    "        dominant_colors.append(colors_in_image.flatten())\n",
    "    #print(image)\n",
    "    #print(dominant_colors)\n",
    "    img_clf = KMeans(random_state=seed,n_clusters = number_of_clusters)\n",
    "    img_clf.fit(np.array(dominant_colors))\n",
    "    return img_clf\n",
    "\n",
    "def plot_color_bar(colors):\n",
    "    bar = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "    for color in colors:\n",
    "        #print (\"color in bar\",color)\n",
    "        endX = startX + (1/len(colors) * 300)\n",
    "        #print(\"the start is\",startX, 'the end is',endX)\n",
    "        cv2.rectangle(bar, (int(startX), 0), (int(endX), 50),color.astype(\"uint8\").tolist(), -1)\n",
    "        startX = endX\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(bar)\n",
    "    plt.show()\n",
    "    return bar\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_of_colors = 3\n",
    "images_clf = cluster_images_based_on_color(train_files,7,number_of_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "colors_clusters = images_clf.cluster_centers_\n",
    "labels = images_clf.labels_\n",
    "print(len(labels))\n",
    "RGB_COLORS_CONSTANT = 3\n",
    "if(number_of_colors>1):\n",
    "    for color in colors_clusters:\n",
    "        plot_color_bar(np.split(color,RGB_COLORS_CONSTANT))\n",
    "else:\n",
    "    for color in colors_clusters:\n",
    "        plot_color_bar(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Colors and Stains:\n",
    "\n",
    "We can observe from the previous clusters that the dataset is stained differently, the differences in coloring. Hence, we'll be using grayscale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print (images_clf)\n",
    "sample_image = cv2.imread(train_files[0])\n",
    "#print (sample_image.shape[1])\n",
    "def get_images_features_list(images_path_array):\n",
    "    images_height = []\n",
    "    images_width = []\n",
    "    images_mean = []\n",
    "    images_std= []\n",
    "    for image_path in images_path_array:\n",
    "        image = cv2.imread(image_path)\n",
    "        images_height.append(image.shape[0])\n",
    "        images_width.append(image.shape[1])\n",
    "        images_mean.append(np.mean(image))\n",
    "        images_std.append(np.std(image))\n",
    "    return images_height,images_width,images_mean,images_std\n",
    "\n",
    "def plot_scatter_plot(X,y):\n",
    "    plt.xlabel(\"Height (px)\")\n",
    "    plt.ylabel(\"Width (px)\")\n",
    "    plt.title(\"Resolution Scatter Plot\")\n",
    "    plt.scatter(X, y)\n",
    "    \n",
    "X,y,means,stdvs = get_images_features_list(train_files)\n",
    "plot_scatter_plot(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "heatmap, xedges, yedges = np.histogram2d(X, y, bins=10)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
    "plt.show()\n",
    "\n",
    "paired = (list(zip(X,y)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(data=paired)\n",
    "#print(df.keys)\n",
    "df.index.name = 'x label'\n",
    "\n",
    "ax = df.plot.hexbin(x=0, y=1, gridsize=5,title=\"Resolution Heatmap\",)\n",
    "ax.set_ylabel(\"Width (px)\")\n",
    "ax.set_xlabel(\"Height (px)\") #bug in juypter notebook doens't show the x-axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from skimage import io, img_as_float\n",
    "import numpy as np\n",
    "\n",
    "image = io.imread('http://i.stack.imgur.com/Y8UeF.jpg')\n",
    "image = img_as_float(image)\n",
    "print(np.mean(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Plot \"Pixel Intensity Means for All Images\" and \"Standard Deviation per Image\"\n",
    "\n",
    "plt.plot(means, np.zeros_like(means), 'x')\n",
    "plt.xlabel(\"Image mean (px)\")\n",
    "plt.title(\"Pixel Intensity Means for All Images\")\n",
    "plt.axes().get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "plt.plot(stdvs, np.zeros_like(stdvs), 'r+')\n",
    "plt.title(\"Images Standard Deviation\")\n",
    "plt.axes().get_yaxis().set_visible(False)\n",
    "plt.xlabel(\"Standard Deviation per Image (px)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Taken from dog-project, Preprocessing for Keras\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (150, 150, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 150, 150, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras, since we need to match the pre-trained enviroment, we divide by 255\n",
    "train_files_tensors = paths_to_tensor(train_files[:100]).astype('float32')/255 \n",
    "#for binder in train_targets_binded:\n",
    "    #targets_tensor = paths_to_tensor(train_targets[:2900]).astype('float32')/255\n",
    "    #for \n",
    "train_target_tensors = paths_to_tensor(train_targets[:2900]).astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Conv2DTranspose\n",
    "from keras.layers import Dropout, Flatten, Dense, Reshape\n",
    "from keras.models import Sequential,Model\n",
    "\n",
    "#TODO bottleneck_features\n",
    "base_model = Xception(input_shape=train_files_tensors.shape[1:],weights='imagenet', include_top=False)\n",
    "\n",
    "xc = base_model.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2DTranspose\n",
    "#xc = GlobalAveragePooling2D()(xc)\n",
    "#xc = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same')(xc)\n",
    "#output = Conv2D(1, (1, 1), activation='sigmoid') (xc)\n",
    "\n",
    "#output = Dense(2, activation='sigmoid')(xc)\n",
    "\n",
    "xc = base_model.output\n",
    "#xc = GlobalAveragePooling2D()(xc)\n",
    "output= Conv2DTranspose(3, (3, 3), strides=(30, 30), padding='same',activation='relu')(xc)\n",
    "#predictions = Dense(100, activation='softmax')(xc)\n",
    "\n",
    "# add your top layer block to your base model\n",
    "Xception_starter_model = Model(base_model.input, output)\n",
    "\n",
    "# freeze Xception layers\n",
    "for layer in model.layers[:132]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(Xception_starter_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Taken from https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277#295658\n",
    "\n",
    "def meanIoU(y_true_batch, y_pred_batch):\n",
    "    return np.mean(np.asarray([IoU(y_pred_batch, y_true_batch,t) for t in np.arange(0.5, 1, 0.05)])) \n",
    "\n",
    "def IoU(y_pred_batch, y_true_batch, threshold):\n",
    "    return np.mean(np.asarray([pixelAccuracy(y_pred_batch[i], y_true_batch[i],threshold) for i in range(len(y_true_batch))])) \n",
    "\n",
    "def pixelAccuracy(y_pred_orig, y_true, threshold):\n",
    "    y_pred = (y_pred_orig > threshold)   \n",
    "    return 1.0 * np.sum((y_pred==y_true)*(y_true>0)) /  (np.sum(y_pred>0) + np.sum(y_true>0) - np.sum((y_pred==y_true)*(y_true>0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Xception_starter_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[meanIoU])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# taken from dog-project\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 5\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.xception_starter.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Xception_starter_model.fit(train_files_tensors, train_files_tensors, validation_split=0.1,\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Xception_detect_nuclei(img_path):\n",
    "    # extract bottleneck features\n",
    "    #bottleneck_feature = extract_VGG16(path_to_tensor(img_path))\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = Xception_starter_model.predict(path_to_tensor(img_path))\n",
    "    # return dog breed that is predicted by the model\n",
    "    return predicted_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(train_files_tensors.shape[1:])\n",
    "print(train_files_tensors[1].shape)\n",
    "plt.imshow(train_files_tensors[1])\n",
    "plt.show()\n",
    "print(train_target_tensors[1].shape)\n",
    "plt.imshow(train_target_tensors[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Sanity Check:\n",
    "predImage = Xception_detect_nuclei(train_files[0])\n",
    "print(predImage[0].shape)\n",
    "#predImage = cv2.imread(pred)\n",
    "plt.imshow(predImage[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dog-project]",
   "language": "python",
   "name": "conda-env-dog-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
